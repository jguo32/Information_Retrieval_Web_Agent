#!/usr/local/bin/perl -w

use strict;

use Carp;
use FileHandle;


##########################################################
##  VECTOR1
##
##  Usage:   vector1     (no command line arguments)
##
##  The function &main_loop below gives the menu for the system.
##
##  This is an example program that shows how the core
##  of a vector-based IR engine may be implemented in Perl.
##
##  Some of the functions below are unimplemented, and some
##  are only partially implemented. Suggestions for additions
##  are given below and in the assignment handout.
##
##  You should feel free to modify this program directly,
##  and probably use this as a base for your implemented
##  extensions.  As with all assignments, the range of
##  possible enhancements is open ended and creativity
##  is strongly encouraged.
##########################################################


############################################################
## Program Defaults and Global Variables
############################################################

my $DIR  = ".";
my $HOME = ".";

my $token_docs = "$DIR/cacm";           # tokenized cacm journals
my $corps_freq = "$DIR/cacm";           # frequency of each token in the journ.
my $stoplist   = "$DIR/common_words";   # common uninteresting words
my $titles     = "$DIR/titles.short";   # titles of each article in cacm 
my $token_qrys = "$DIR/query";          # tokenized canned querys
my $query_freq = "$DIR/query";          # frequency of each token in the querys
my $query_relv = "$DIR/query\.rels";    # relevance of a journal entry to a
                                        #  given query

# these files are created in your $HOME directory

my $token_intr = "$HOME/interactive";    # file created for interactive queries
my $inter_freq = "$HOME/interactive";    # frequency of each token in above

###########################################################
## Customized Variables
###########################################################
my $total_docs = undef;
my $total_qrys = undef;

my @result_list = ();	# Averaged result of the 8 measures over 33 queries

my $prec_mean1 = undef;
my $prec_mean2 = undef;
my $recall_norm = undef;
my $prec_norm = undef;

my %rel_rank = ();		# hash map of relevant doc# -> rank	

my @rel_list = ();	# list of relevant doc with order
my @recall = ();
my @precision = ();	# recall/precision pair of each relevant document
					# ordered by relevance (high -> low)

###########################################################
## Customized Variables
###########################################################


# @doc_vector
#
#   An array of hashes, each array index indicating a particular document's
#   weight "vector". 

my @doc_vector = ( );

# @qry_vector
#
#   An array of hashes, each array index indicating a particular query's
#   weight "vector".

my @qry_vector = ( );

# %docs_freq_hash
#
# associative array which holds <token, frequency> pairs where
#
#   token     = a particular word or tag found in the cacm corpus
#   frequency = the total number of times the token appears in
#               the corpus.

my %docs_freq_hash = ( );    

# %corp_freq_hash
#
# associative array which holds <token, frequency> pairs where
#
#   token     = a particular word or tag found in the corpus
#   frequency = the total number of times the token appears per
#               document-- that is a token is counted only once
#               per document if it is present (even if it appears 
#               several times within that document).

my %corp_freq_hash = ( );

# %stoplist_hash
#
# common list of uninteresting words which are likely irrelvant
# to any query.
#
#   Note: this is an associative array to provide fast lookups
#         of these boring words

my %stoplist_hash  = ( );

# @titles_vector
#
# vector of the cacm journal titles. Indexed in order of apperance
# within the corpus.

my @titles_vector  = ( );

# %relevance_hash
#
# a hash of hashes where each <key, value> pair consists of
#
#   key   = a query number
#   value = a hash consisting of document number keys with associated
#           numeric values indicating the degree of relevance the 
#           document has to the particular query.

my %relevance_hash = ( );

# @doc_simula
#
# array used for storing query to document or document to document
# similarity calculations (determined by cosine_similarity, etc. )

my @doc_simula = ( );

# @res_vector
#
# array used for storing the document numbers of the most relevant
# documents in a query to document or document to document calculation.

my @res_vector = ( );

 
# start program

&main_loop;

##########################################################
##  INIT_FILES
##
##  This function specifies the names and locations of
##  input files used by the program. 
##
##  Parameter:  $type   ("stemmed" or "unstemmed")
##
##  If $type == "stemmed", the filenames are initialized
##  to the versions stemmed with the Porter stemmer, while
##  in the default ("unstemmed") case initializes to files
##  containing raw, unstemmed tokens.
##########################################################

sub init_files {

    if ("stemmed" eq (shift || "")) {

		$token_docs = "$DIR/cacm\.stemmed";
		$corps_freq = "$DIR/cacm\.stemmed\.hist";
		$stoplist   = "$DIR/common_words\.stemmed";
		$token_qrys = "$DIR/query\.stemmed";
		$query_freq = "$DIR/query\.stemmed\.hist";
		$token_intr = "$DIR/interactive\.stemmed";
		$inter_freq = "$DIR/interactive\.stemmed\.hist";
    }
    else {

		$token_docs = "$DIR/cacm\.tokenized";
		$corps_freq = "$DIR/cacm\.tokenized\.hist";
		$token_qrys = "$DIR/query\.tokenized";
		$query_freq = "$DIR/query\.tokenized\.hist";
		$token_intr = "$DIR/interactive\.tokenized";
		$inter_freq = "$DIR/interactive\.tokenized\.hist";
    }
}

##########################################################
##  INIT_CORP_FREQ 
##
##  This function reads in corpus and document frequencies from
##  the provided histogram file for both the document set
##  and the query set. This information will be used in
##  term weighting.
##
##  It also initializes the arrays representing the stoplist,
##  title list and relevance of document given query.
##########################################################

sub init_corp_freq {
	%docs_freq_hash = ();
	%corp_freq_hash = ();
	%stoplist_hash = ();
	@titles_vector = ();
	%relevance_hash = ();

	my $include_stopword = shift;

    my $corps_freq_fh = new FileHandle $corps_freq, "r" 
	or croak "Failed $corps_freq";

    my $query_freq_fh = new FileHandle $query_freq, "r"
	or croak "Failed $query_freq";

    my $stoplist_fh   = new FileHandle $stoplist  , "r"
	or croak "Failed $stoplist";

    my $titles_fh     = new FileHandle $titles    , "r"
	or croak "Failed $titles";

    my $query_relv_fh = new FileHandle $query_relv, "r"
	or croak "Failed $query_relv";

    my $line = undef;

    while (defined( $line = <$corps_freq_fh> )) {

		# so on my computer split will return a first element of undef 
		# if the leading characters are white space, so I eat the white
		# space to insure that the split works right.

		my ($str) = ($line =~ /^\s*(\S.*)/);

		my ($doc_freq,
	    	$cor_freq, 
	    	$term    ) = split /\s+/, $str;

		$docs_freq_hash{ $term } = $doc_freq;
		$corp_freq_hash{ $term } = $cor_freq;
    }
    

    while (defined( $line = <$query_freq_fh> )) {

		my ($str) = ($line =~ /^\s*(\S.*)/);

		my ($doc_freq,
	    	$cor_freq,
	    	$term    ) = split /\s+/, $str;

		$docs_freq_hash{ $term } += $doc_freq;
		$corp_freq_hash{ $term } += $cor_freq;
    }

    if (!defined( $include_stopword ) || $include_stopword !~ /0/) {
	    while (defined( $line = <$stoplist_fh> )) {

			chomp $line;
			$stoplist_hash{ $line } = 1;
	    }
    }


    push @titles_vector, "";       # push one empty value onto @titles_vector
                                   # so that indices correspond with title
                                   # numbers.

    while (defined( $line = <$titles_fh> )) {

	chomp $line;
	push @titles_vector, $line;
    }


    while (defined( $line = <$query_relv_fh> )) {

	my ($str) = ($line =~ /^\s*(\S.*)/);

	my ($qry_num,
	    $rel_doc)  = split /\s+/, $str;

	$relevance_hash{ "$qry_num" }{ "$rel_doc" } = 1;
    }
}



##########################################################
##  INIT_DOC_VECTORS
##
##  This function reads in tokens from the document file.
##  When a .I token is encountered, indicating a document
##  break, a new vector is begun. When individual terms
##  are encountered, they are added to a running sum of
##  term frequencies. To save time and space, it is possible
##  to normalize these term frequencies by inverse document
##  frequency (or whatever other weighting strategy is
##  being used) while the terms are being summed or in
##  a posthoc pass.  The 2D vector array 
##
##    $doc_vector[ $doc_num ]{ $term }
##
##  stores these normalized term weights.
##
##  It is possible to weight different regions of the document
##  differently depending on likely importance to the classification.
##  The relative base weighting factors can be set when 
##  different segment boundaries are encountered.
##
##  This function is currently set up for simple TF weighting.
##########################################################

sub init_doc_vectors {

	@doc_vector = ();

	my $init_type = shift;
	
    my $TITLE_BASE_WEIGHT = shift;     # weight given a title token
    my $KEYWD_BASE_WEIGHT = shift;     # weight given a key word token
    my $ABSTR_BASE_WEIGHT = shift;     # weight given an abstract word token
    my $AUTHR_BASE_WEIGHT = shift;     # weight given an an author token
	
	if(!defined($TITLE_BASE_WEIGHT) ) {
		$TITLE_BASE_WEIGHT = 3;
	}
	if(!defined($KEYWD_BASE_WEIGHT) ) {
		$KEYWD_BASE_WEIGHT = 4;
	}
	if(!defined($ABSTR_BASE_WEIGHT) ) {
		$ABSTR_BASE_WEIGHT = 2;
	}
	if(!defined($AUTHR_BASE_WEIGHT) ) {
		$AUTHR_BASE_WEIGHT = 10;
	}

    my $token_docs_fh = new FileHandle $token_docs, "r"
	or croak "Failed $token_docs";

    my $word    = undef;

    my $doc_num =  0;    # current document number and total docs at end
    my $tweight =  0;    # current weight assigned to document token

    push @doc_vector, { };     # push one empty value onto @doc_vector so that
                               # indices correspond with document numbers

    while (defined( $word = <$token_docs_fh> )) {
	
		chomp $word;

		last if $word =~ /^\.I 0/; # indicates end of file so kick out
	
		if ($word =~ /^\.I/) {     # indicates start of a new document

		    push @doc_vector, { };
	    	$doc_num++;
	   		next;
		}
	
		$tweight = $TITLE_BASE_WEIGHT and next if $word =~ /^\.T/;
		$tweight = $KEYWD_BASE_WEIGHT and next if $word =~ /^\.K/;
		$tweight = $ABSTR_BASE_WEIGHT and next if $word =~ /^\.W/;
		$tweight = $AUTHR_BASE_WEIGHT and next if $word =~ /^\.A/;

		if (defined($init_type) && $init_type =~ /all/) {
			if ($word =~ /./ ) {
			    if (defined( $docs_freq_hash{ $word } )) {
					$doc_vector[$doc_num]{ $word } += $tweight;
			    }
			    else {
					print "ERROR: Document frequency of zero: ", $word, "\n";
			    }
			}
		}
		elsif (defined($init_type) && $init_type =~ /boolean/) {
			if ($word =~ /[a-zA-Z]/ and ! exists $stoplist_hash{ $word }) {
				if (defined( $docs_freq_hash{ $word } )) {
					$doc_vector[$doc_num]{ $word } = 1;
				}
				else {
					$doc_vector[$doc_num]{ $word } = 0;
					#print "ERROR: Document frequency of zero: ", $word, "\n";
				}
			}
		}
		else {
			if ($word =~ /[a-zA-Z]/ and ! exists $stoplist_hash{ $word }) {
				if (defined( $docs_freq_hash{ $word } )) {
					$doc_vector[$doc_num]{ $word } += $tweight;
				}
				else {
					print "ERROR: Document frequency of zero: ", $word, "\n";
				}
			}
		}

    }

	if (!defined($init_type) || $init_type !~ /raw_tf/) {
		foreach my $hash (@doc_vector) {
    	 	foreach my $key (keys %{ $hash }) {
   	     		$hash->{ $key } = $hash->{ $key } * log( $doc_num / $docs_freq_hash{ $key });
				#print "tf idf weight for $key is $hash->{ $key }\n";
        	}
    	}
    }

    return $doc_num;
}


##########################################################
##  INIT_QRY_VECTORS
##
##  This function should be nearly identical to the step
##  for initializing document vectors.
##
##  This function is currently set up for simple TF weighting.
##########################################################

sub init_qry_vectors {
	@qry_vector = ();
	my $init_type = shift;

    my $QUERY_BASE_WEIGHT = 1;
    my $QUERY_AUTH_WEIGHT = 1;

    my $token_qrys_fh = new FileHandle $token_qrys, "r"
	or croak "Failed $token_qrys";

    my $word = undef;

    my $tweight =  0;
    my $qry_num =  0;

    push @qry_vector, { };    # push one empty value onto @qry_vectors so that
                              # indices correspond with query numbers

    while (defined( $word = <$token_qrys_fh> )) {

		chomp $word;

		if ($word =~ /^\.I/) {
			
			push @qry_vector, { };
			$qry_num++;

			next;
		}

		$tweight = $QUERY_BASE_WEIGHT and next if $word =~ /^\.W/;
		$tweight = $QUERY_AUTH_WEIGHT and next if $word =~ /^\.A/;

		if (defined($init_type) && $init_type =~ /all/) {
			if ($word =~ /./)  {
			    if (! exists $docs_freq_hash{ $word }) {
					print "ERROR: Document frequency of zero: ", $word, "\n";
			    }
			    else {
					$qry_vector[$qry_num]{ $word } += $tweight;
			    }
			}
		}
		else {
			if ($word =~ /[a-zA-Z]/ && ! exists $stoplist_hash{ $word }) {
				if (! exists $docs_freq_hash{ $word }) {
					print "ERROR: Document frequency of zero: ", $word, "\n";
				}
				else {
					$qry_vector[$qry_num]{ $word } += $tweight;
				}
			}
		}

    }

    if (!defined($init_type) || $init_type !~ /raw_tf/) {
		foreach my $hash (@qry_vector) {
		  foreach my $key (keys %{ $hash }) {
		     $hash->{ $key } = $hash->{ $key } * log( $total_docs / $docs_freq_hash{ $key });
		 }
		}
 	}
    return $qry_num;
}

sub init_boolean_qry_vectors {
	@qry_vector = ();

    my $token_qrys_fh = new FileHandle $token_qrys, "r"
	or croak "Failed $token_qrys";

    my $word = undef;

    my $tweight =  0;
    my $qry_num =  0;

    push @qry_vector, { };    # push one empty value onto @qry_vectors so that
                              # indices correspond with query numbers

    while (defined( $word = <$token_qrys_fh> )) {

		chomp $word;

		if ($word =~ /^\.I/) {
			
			push @qry_vector, { };
			$qry_num++;

			next;
		}

		if ($word =~ /[a-zA-Z]/ && ! exists $stoplist_hash{ $word }) {

			if (! exists $docs_freq_hash{ $word }) {
				$qry_vector[$qry_num]{ $word } = 0;
			#	print "ERROR: Document frequency of zero: ", $word, "\n";
			}
			else {
				$qry_vector[$qry_num]{ $word } = 1;
			}
		}
    }

    return $qry_num;
}

##########################################################
## MAIN_LOOP
##
## Parameters: currently no explicit parameters.
##             performance dictated by user imput.
## 
## Initializes document and query vectors using the
## input files specified in &init_files. Then offers
## a menu and switch to appropriate functions in an
## endless loop.
## 
## Possible extensions at this level:  prompt the user
## to specify additional system parameters, such as the
## similarity function to be used.
##
## Currently, the key parameters to the system (stemmed/unstemmed,
## stoplist/no-stoplist, term weighting functions, vector
## similarity functions) are hardwired in.
##
## Initializing the document vectors is clearly the
## most time consuming section of the program, as 213334 
## to 258429 tokens must be processed, weighted and added
## to dynamically growing vectors.
## 
##########################################################

sub main_loop {

    print "INITIALIZING VECTORS ... \n";
    print << "EndOfMenu";

    Choose stem type
        (1) Stemmed by Porter stemmer
	(2) Raw unstemmed
	The default choice is stemmed.
EndOfMenu
    ;

    print "Choice: ";

    my    $stem_type = <STDIN>;
    chomp $stem_type;

    if ($stem_type !~ /^[1-2]$/) { $stem_type = 1; }
	if ($stem_type == 1) { &init_files ( "stemmed" ); }
	if ($stem_type == 2) { &init_files ( "unstemmed" ); }
	
	print << "EndOfMenu";
    Choose if exclude stopwords or not:
        (1) Exclude stopwords 
	(2) include all tokens
	The default choice is excluding stopwords.
EndOfMenu
    ;
	print "Choice: ";

    my    $stopword_type = <STDIN>;
    chomp $stopword_type;
	if ($stopword_type !~ /^[1-2]$/) { $stopword_type = 1; }
	if ($stopword_type == 1) { &init_corp_freq; }
	if ($stopword_type == 2) { &init_corp_freq(0); }
 
    print << "EndOfMenu";

    Choose term weighting permutations:
        (1) Raw TF weighting 
	(2) TF IDF weighting
	(3) Boolean weighting
	The default choice is TF IDF weighting.
EndOfMenu
    ;
	print "Choice: ";

    my    $weight_type = <STDIN>;
    chomp $weight_type;

    if ($weight_type !~ /^[1-3]$/) { $weight_type = 2; }
	if ($weight_type == 1) { 
		$total_docs = &init_doc_vectors("raw_tf");
		$total_qrys = &init_qry_vectors("raw_tf");
	}
	if ($stem_type == 3) {
		$total_docs = &init_doc_vectors("boolean");
		$total_qrys = &init_boolean_qry_vectors;
	}
	else {
		print << "EndOfMenu";

		Choose region weighting permutations:
			(1) Use relative weights of titles=3x, keywords = 4x, author=3x, abstract=1x (default)
		(2) Equal weighting
		(3) Use relative weights of titles=1x, keywords = 1x, author=1x, abstract=4x
		The default choice is TF IDF weighting.
EndOfMenu
		;
		print "Choice: ";
		my    $region_weight_type = <STDIN>;
		chomp $region_weight_type;

		if ($region_weight_type !~ /^[1-3]$/) { $region_weight_type = 1; }
		if ($region_weight_type == 2) { 
			$total_docs = &init_doc_vectors("default",1,1,1,1);
		}
		if ($region_weight_type == 3) {
			$total_docs = &init_doc_vectors("default", 1,1,1,4);
		}		
		else {
			$total_docs = &init_doc_vectors;
		}
		$total_qrys = &init_qry_vectors;
	}
    
    while (1) {

	print <<"EndOfMenu";

	============================================================
	==     Welcome to the 600.466 Vector-based IR Engine
	==                                                  
        == Total Documents: $total_docs                     
	== Total Queries:   $total_qrys                     
	============================================================

	OPTIONS:
	  1 = Find documents most similar to a given query or document
	  2 = Compute precision/recall for the full query set
	  3 = Compute cosine similarity between two queries/documents
	  4 = Quit

	============================================================

EndOfMenu
    ;

	print "Enter Option: ";

	my    $option = <STDIN>;
	chomp $option;

	exit 0 if $option == 4;

	&full_precision_recall_test and next if $option == 2;
	&do_full_cosine_similarity  and next if $option == 3;

	# default and choice 1 is

	&get_and_show_retrieved_set and next if ($option != 2 && $option != 3);
    } 
}


##########################################################
## GET_AND_SHOW_RETRIEVED_SET
##   
##  This function requests key retrieval parameters,
##  including:
##  
##  A) Is a query vector or document vector being used
##     as the retrieval seed? Both are vector representations
##     but they are stored in different data structures,
##     and one may optionally want to treat them slightly
##     differently.
##
##  B) Enter the number of the query or document vector to
##     be used as the retrieval seed.
##
##     Alternately, one may wish to request a new query
##     from standard input here (and call the appropriate
##     tokenization, stemming and term-weighting routines).
##
##  C) Request the maximum number of retrieved documents
##     to display.
##
##  Perl note: one reads a line from a file <FILE> or <STDIN>
##             by the assignment $string=<STDIN>; Beware of
##             string equality testing, as these strings 
##             will have a newline (\n) attached.
##########################################################

sub get_and_show_retrieved_set {

    print << "EndOfMenu";

    Find documents similar to:
        (1) a query from 'query.raw'
	(2) an interactive query
	(3) another document
EndOfMenu
    ;

    print "Choice: ";

    my    $comp_type = <STDIN>;
    chomp $comp_type;

    if   ($comp_type !~ /^[1-3]$/) { $comp_type = 1; }

    print "\n";
	
    # if not an interactive query then we need to retrieve which
    # query/document we want to use from the corpus
    
    my $vect_num = 1;

    if ($comp_type != 2) {
		print "Target Document/Query number: ";

			  $vect_num  = <STDIN>;
		chomp $vect_num;

		if   ($vect_num !~ /^[1-9]/) { $vect_num  = 1; }
		if ($comp_type == 1 && $vect_num > 33) {
			$vect_num = 33;
		}
			
		print "\n";
    }

    print "Show how many matching documents (20): ";
    
    my    $max_show  = <STDIN>;
    chomp $max_show;

    if   ($max_show !~ /[0-9]/) { $max_show  = 20; }

    if    ($comp_type == 3) {

		print "Document to Document comparison\n";
		
		&get_retrieved_set( $doc_vector[$vect_num]);
		&shw_retrieved_set( $max_show, 
					$vect_num, 
					$doc_vector[$vect_num],
					"Document" );
    }
    elsif ($comp_type == 2) {
	
		print "Interactive Query to Document comparison\n";

		my $int_vector = &set_interact_vec;  # vector created by interactive
												 #  query

		&get_retrieved_set( $int_vector);
		&shw_retrieved_set( $max_show,
					0,
					$int_vector,
					"Interactive Query" );
    }
    else {

		print "Query to Document comparison\n";

		&get_retrieved_set( $qry_vector[$vect_num]);
		&shw_retrieved_set( $max_show,
					$vect_num,
					$qry_vector[$vect_num],
					"Query" );
		
		&comp_recall( $relevance_hash{ $vect_num },
				  $vect_num );
		&show_relvnt( $relevance_hash{ $vect_num },
				  $vect_num,
				  $qry_vector[$vect_num] );
    }
}


sub set_interact_vec {

    system "$DIR/interactive.prl" and die "Failed $DIR/interactive.prl: $!\n";

    my $QUERY_BASE_WEIGHT = 2;
    my $QUERY_AUTH_WEIGHT = 2;

    my $token_qrys_fh = new FileHandle $token_intr, "r"
	or croak "Failed $token_intr";

    my $int_vector = { };
    my $word       = undef;

    my $tweight =  0;
    my $qry_num =  0;

    while (defined( $word = <$token_qrys_fh> )) {

	chomp $word;
	print $word, "\n";

	next if $word =~ /^\.I/;   # start of query tokens

	$tweight = $QUERY_BASE_WEIGHT and next if $word =~ /^\.W/;
	$tweight = $QUERY_AUTH_WEIGHT and next if $word =~ /^\.A/;

	if ($word =~ /[a-zA-Z]/ && ! exists $stoplist_hash{ $word }) {

	    if (! exists $docs_freq_hash{ $word }) {
	#	print "ERROR: Document frequency of zero: ", $word, "\n";
	    }
	    else {
		$$int_vector{ $word } += $tweight;
	    }
	}
    }

   	 foreach my $key (keys %{ $int_vector }) {
     	$int_vector->{ $key } = $int_vector->{ $key } * log( $total_docs / $docs_freq_hash{ $key });
	}


    return $int_vector;
}

    
###########################################################
## GET_RETRIEVED_SET
##
##  Parameters:
## 
##  $qry_vector{} - the query vector to be compared with the
##                  document set. May also be another document 
##                  vector.
##
##  This function computes the document similarity between the
##  given vector $qry_vector{} and all vectors in the document
##  collection storing these values in the array @doc_simula
##
##  An array of the document numbers is then sorted by this
##  similarity function, forming the rank order of documents
##  for use in the retrieval set.  
##
##  The -1 in the simcomp similarity comparision function
##  makes the sorted list in descending order.
##########################################################
 
sub get_retrieved_set {

    my $qry_vector = shift;
    my $tot_number = (scalar @doc_vector) - 1;
    my $index      = 0;
	
	my $similarity_type = shift;

    @doc_simula = ( );   # insure that storage vectors are empty before we
    @res_vector = ( );   # calculate vector similarities

    push @doc_simula, 0.0;    # push one empty value so that indices 
                              # correspond with document values
	if (!defined($similarity_type)) {			  
		print << "EndOfMenu";
		Choose the similarity type:
		(1) Cosine similarity
		(2) Dice similarity
		The default choice is Cosine similarity.
EndOfMenu
		;
		print "Choice: ";

		$similarity_type = <STDIN>;
		chomp $similarity_type;
		if ($similarity_type !~ /^[1-2]$/) { $similarity_type = 1; }
		if ($similarity_type == 1) { $similarity_type = "cosine"; }
		elsif ($similarity_type == 2) { $similarity_type = "dice"; }
	}
    for $index ( 1 .. $tot_number) {
		if (defined($similarity_type) && $similarity_type eq "dice") {
			push @doc_simula, &dice_sim( $qry_vector, $doc_vector[$index] );
		}
		else {
			push @doc_simula, &cosine_sim_a( $qry_vector, $doc_vector[$index] );
		}
    }

    @res_vector = 
      sort { -1 * ($doc_simula[$a] <=> $doc_simula[$b]); } 1 .. $tot_number;
}
    
############################################################
## SHW_RETRIEVED_SET
##
## Assumes the following global data structures have been
## initialized, based on the results of &get_retrieved_set.
##
## 1) @res_vector - contains the document numbers sorted in 
##                  rank order
## 2) @doc_simula - The similarity measure for each document, 
##                  computed by &get_retrieved_set.
##
## Also assumes that the following have been initialized in
## advance:
##
##       $titles[ $doc_num ]    - the document title for a 
##                                document number, $doc_num
##       $relevance_hash{ $qry_num }{ $doc_num }
##                              - is $doc_num relevant given
##                                query number, $qry_num
##
## Parameters:
##   $max_show   - the maximum number of matched documents 
##                 to display.
##   $qry_num    - the vector number of the query
##   $qry_vect   - the query vector (passed by reference)
##   $comparison - "Query" or "Document" (type of vector 
##                 being compared to)
##
## In the case of "Query"-based retrieval, the relevance 
## judgements for the returned set are displayed. This is 
## ignored when doing document-to-document comparisons, as 
## there are nor relevance judgements.
##
############################################################

sub shw_retrieved_set {

    my $max_show   = shift;
    my $qry_num    = shift;
    my $qry_vect   = shift;
    my $comparison = shift;

    print << "EndOfList";

    ************************************************************
	Documents Most Similar To $comparison number $qry_num
    ************************************************************
    Similarity   Doc#  Author      Title
    ==========   ==== ========     =============================

EndOfList
    ;

    my $rel_num = ($qry_num =~ /^\d$/) ? "0$qry_num" : $qry_num;
    my $index   = 0;

    for $index ( 0 .. $max_show - 1) {
		my $ind = $res_vector[$index];

		if (($comparison =~ /Query/) and 
			($relevance_hash{ $rel_num }{ $ind })) {
			print "\* ";
		}
		else {
			print "  ";
		}

		my ($similarity) = ($doc_simula[$ind]    =~ /^([0-9]+\.\d{0,8})/);
		if($doc_simula[$ind] == 0 or $doc_simula[$ind] == 1) {
			$similarity = sprintf "%0.8f", $doc_simula[$ind];
	    }
		my  $title       = substr $titles_vector[$ind], 0, 47;

		print "  ", $similarity, "   ", $title, "\n";
    }

    print "\n";
    print "Show the terms that overlap between the query and ";
    print "retrieved docs (y/n): ";

    my  $show_terms = <STDIN>;
    if ($show_terms !~ /[nN]/) {

		my $index = 0;

		for $index ( 0 .. $max_show - 1 ) {
			my $ind = $res_vector[$index];

			show_overlap( $qry_vect,
				  $doc_vector[$ind],
				  $qry_num,
				  $ind );

			if ($index % 5 == 4) {

				print "\n";
				print "Continue (y/n)? ";

				my  $cont = <STDIN>;
				if ($cont =~ /[nN]/) {
					last;
				}
			}
		}
    }
	
	print "\n";
    print "Cluster the top k documents? (y/n): ";
	
	my $show_cluster = <STDIN>;
	if ($show_cluster !~ /[nN]/) {
		print "\n";
		print "Specify the value of k, or skip it to specify similarity later: ";
		my $cluster_doc_num = <STDIN>;
		chomp $cluster_doc_num;

		if ($cluster_doc_num !~ /[0-9]+/) {
			&cluster_doc($rel_num);
		}
		else {
			&cluster_doc($rel_num, $cluster_doc_num);
		}
		
	}
	
	
}
##########################################################
## CLUSTER_DOC
##
## Cluster the top k returned documents
##
##########################################################

sub cluster_doc {
	my $rel_num = shift;
	my $doc_count = shift;
	my $sim_bar;
	my $sim;

	my @docs_to_cluster = ();
	my @centroids = ();
	my @clusters = ();

	
	if (!defined($doc_count)) {
		print "\n";
		print "Please specify the similarity: ";
		$sim_bar = <STDIN>;
		chomp $sim_bar;
		while ($sim_bar !~ /[0-9]+(\.[0-9]+)?/) {
			print "\n";
			print "Invalid number, please specify again: ";
			$sim_bar = <STDIN>;
			chomp $sim_bar;
		}

		my $index = 0;
		while($doc_simula[$res_vector[$index]] >= $sim_bar) {
			push @docs_to_cluster, $res_vector[$index];
			$index++;
		}		

	}
	else {
		for (my $i = 0; $i < $doc_count; $i++) {
			push @docs_to_cluster, $res_vector[$i];
		}
	}

	# first cluster, whose centroid is the vector of retrieved document
	# with highest similarity (first one in the list)
	push @centroids, $doc_vector[$docs_to_cluster[0]];
	push @{$clusters[0]}, $docs_to_cluster[0];
	my $cnt_sim_bar = $doc_simula[$clusters[0][0]];
	
	print "current sim bar by doc $docs_to_cluster[0]: $cnt_sim_bar\n";
	
	for (my $i = 1; $i < scalar @docs_to_cluster; $i++) {
		for (my $j = 0; $j < scalar @clusters; $j++) {
			$cnt_sim_bar = $doc_simula[$clusters[$j][0]];
			$sim = &cosine_sim_a( $doc_vector[$docs_to_cluster[$i]], $centroids[$j]);
			# print "the sim of $docs_to_cluster[$i] and $clusters[$j][0] is $sim\n";
			
			if ($sim > $cnt_sim_bar) {
				push @{$clusters[$j]}, $docs_to_cluster[$i];
				$centroids[$j] = &cal_centroid(@{$clusters[$j]});
				last;
			}

			# Current doc doesn't belong to any cluster, so create one
			if ($j == (scalar @clusters - 1)) {
				push @centroids, $doc_vector[$docs_to_cluster[$i]];
				push @{$clusters[$j + 1]}, $docs_to_cluster[$i];
				last;
			}
		}
	}
	
	&show_clusters($rel_num, \@clusters);
	
}

sub show_clusters {

	my $rel_num = shift;
	my $clusters_temp = shift;
	my @clusters = @{$clusters_temp};
	
    print << "EndOfList";

    ************************************************************
	Clustering result of query number $rel_num
    ************************************************************

EndOfList
    ;

    my $i = 0;

    for $i ( 0 .. scalar @clusters - 1) {

		my @cluster = @{$clusters[$i]};
		my $cluster_size = scalar @cluster;
    print << "EndOfList";

    ************************************************************
	Cluster number $i, size: $cluster_size
    ************************************************************
    Similarity   Doc#  Author      Title
    ==========   ==== ========     =============================

EndOfList
    ;	
		for my $j (0 .. scalar @cluster - 1) {
			my $ind = $cluster[$j];

			if (($relevance_hash{ $rel_num }{ $ind })) {
				print "\* ";
			}
			else {
				print "  ";
			}

			my ($similarity) = ($doc_simula[$ind]    =~ /^([0-9]+\.\d{0,8})/);
			if($doc_simula[$ind] == 0 or $doc_simula[$ind] == 1) {
				$similarity = sprintf "%0.8f", $doc_simula[$ind];
			}
			my  $title       = substr $titles_vector[$ind], 0, 47;

			print "  ", $similarity, "   ", $title, "\n";
		}
		print "    ************************************************************\n";

    	&show_salient_terms(@cluster);


    }
    print "\n\n";
}

##########################################################
## SHOW_SALIENT_TERMS
## Show the salient terms of current cluster
##########################################################

sub show_salient_terms {
	my @cluster = shift;
	my %terms;

	for my $i (0 .. scalar @cluster - 1) {
		my $cnt = $doc_vector[$cluster[$i]];
		while (my ($term, $weight) = each %{$cnt}) {
			$terms{$term} += $weight;
		}
	}

	my @sorted_terms = sort {$terms{$b} <=> $terms{$a}} keys {%terms};
	my @sorted_weights = @terms{@sorted_terms}; 

	print "    Salient terms: \n";
 	
    print "    ============================================================\n";
    printf( "    %-15s  %-12s %-10s\t\n", 
	   "Terms",
	   #"Query Weight"       ,
	   	"Doc Weight"      ,
	   "Docfreq");    
	for my $i (0 .. 4) {
		printf( "    %-15s  %0.8f  \t%d\n"    ,
		   $sorted_terms[$i]            ,
		   $sorted_weights[$i]          ,
		   $docs_freq_hash{ $sorted_terms[$i] } ,
		   );
		#print "Terms: $sorted_terms[$i]    Weight: $sorted_weights[$i]\n ";
	}
	print "    ============================================================\n";
}

##########################################################
## CAL_CENTROID
##
## Calculate the centroid vector of current cluster
##
##########################################################

sub cal_centroid {
	my @cluster = shift;
	
	my %centroid = ();
	
	for (my $i = 0; $i < scalar @cluster; $i++) {
		my $cnt = $doc_vector[$cluster[$i]];
		
		while (my ($term, $weight) = each %{$cnt}) {
			$centroid{$term} += $weight;
		}
	}
	
	while (my ($term, $weight) = each %centroid) {
		$centroid{$term} = $centroid{$term} / (scalar @cluster);
	}
	
	return \%centroid;
}

##########################################################
## COMPUTE_PREC_RECALL
##
## Like &shw_retrieved_set, this function makes use of the following
## data structures which may either be passed as parameters or
## used as global variables. These values are set by the function
## &get_retrieved_set.
##
## 1) doc_simila[ $rank ] - contains the document numbers sorted 
##                          in rank order based on the results of 
##                          the similarity function
##
## 2) res_vector[ $docn ] - The similarity measure for each document, 
##                          relative to the query vector ( computed by 
##                          &get_retrieved_set).
##
## Also assumes that the following have been initialzied in advance:
##       $titles[ $docn ]       - the document title for a document 
##                                number $docn
##       $relevance_hash{ $qvn }{ $docn } 
##                              - is $docn relevant given query number 
##                                $qvn
##
##  The first step of this function should be to take the rank ordering
##  of the documents given a similarity measure to a query 
##  (i.e. the list docs_sorted_by_similarity[$rank]) and make a list 
##  of the ranks of just the relevant documents. In an ideal world,
##  if there are k=8 relevant documents for a query, for example, the list 
##  of rank orders should be (1 2 3 4 5 6 7 8) - i.e. the relevant documents
##  are the top 8 entries of all documents sorted by similarity.
##  However, in real life the relevant documents may be ordered
##  much lower in the similarity list, with rank orders of
##  the 8 relevant of, for example, (3 27 51 133 159 220 290 1821).
##  
##  Given this list, compute the k (e.g. 8) recall/precison pairs for
##  the list (as discussed in class). Then to determine precision
##  at fixed levels of recall, either identify the closest recall
##  level represented in the list and use that precision, or
##  do linear interpolation between the closest values.
##
##  This function should also either return the various measures
##  of precision/recall specified in the assignment, or store
##  these values in a cumulative sum for later averaging.
##########################################################

sub comp_recall {
    %rel_rank = ();		# hash map of relevant doc# -> rank	
	@recall = ();
	@precision = ();

    my $rel_hash = shift;	# useless
    my $qry_num = shift;
    
    my $rel_num = ($qry_num =~ /^\d$/) ? "0$qry_num" : $qry_num;
    my $rel_count = keys $relevance_hash{$rel_num};

    @rel_list = 
    	sort { -1 * ($doc_simula[$a] <=> $doc_simula[$b]); } keys $relevance_hash{$rel_num};
    
	# get the real rand of these relevant docs
    for my $doc (@rel_list) {
		my $i = 0;
		while ($res_vector[$i] != $doc) {
	   		$i++;
		}
		$rel_rank{$doc} = $i+1; 
    } 
    
#    print << "EndOfList";
#
#    ************************************************************
#	Recall & Precision of each relevant document
#    ************************************************************
#
#EndOfList
#    ;

   

    for (my $i = 0; $i < scalar @rel_list; $i++) {
		$recall[$i] = ($i + 1)/$rel_count;
		my $rank = $rel_rank{$rel_list[$i]};
		$precision[$i] = ($i + 1)/$rank;

		my $rec = sprintf "%0.3f", $recall[$i];
		my $prec = sprintf "%0.3f", $precision[$i]; 
		my $index = $i + 1;
#		print "i= $index\tRank=\t$rank\tRec= $rec\tPREC= $prec\tDoc#= $rel_list[$i]\n";

	}
	

    # Precision mean 1
    $prec_mean1 = (&cal_prec_mean(0.25)+&cal_prec_mean(0.5)+&cal_prec_mean(0.75))/3;

    # Precision mean 2
    my $temp = 0;
	for my $i (1 .. 10) {
		$temp += &cal_prec_mean($i / 10);
	}
	$prec_mean2 = $temp / 10;


    # Recall norm
	$recall_norm = &cal_recall_norm;

    # Prec norm
	$prec_norm = &cal_prec_norm;

	# Fill up the result array to compute features over all 33 queries
	$result_list[0] += &cal_prec_mean(0.25);
	$result_list[1] += &cal_prec_mean(0.5);
	$result_list[2] += &cal_prec_mean(0.75);
	$result_list[3] += &cal_prec_mean(1.00);
	$result_list[4] += $prec_mean1;
	$result_list[5] += $prec_mean2;
	$result_list[6] += $prec_norm;
	$result_list[7] += $recall_norm;

}

sub cal_prec_mean{
	my $level = shift;
	my $length = keys %rel_rank;
	my $temp_prec = 0;

	if ($length == 1) {
		return $precision[0]; 
	}

	for (my $i = 0; $i < $length; $i++) {
		if ($recall[0] > $level) {
			$temp_prec = ($precision[1] - $precision[0])*($level - $recall[0])/				($recall[1] - $recall[0]) + $precision[0];
		}

		if ($recall[$length - 1] < $level) {
			$temp_prec = ($precision[$length - 1] - $precision[$length - 2])*
				($level - $recall[$length - 2]) / ($recall[$length - 1] - $recall[$length - 2]) + $precision[$length - 2];
		}

		if (($recall[$i] < $level) && ($recall[$i + 1] > $level)) {
			$temp_prec = ($precision[$i + 1] - $precision[$i]) * ($level - $recall[$i]) / ($recall[$i + 1] - $recall[$i]) + $precision[$i];
		}
	}
	
	return $temp_prec;
}

sub cal_recall_norm {
	my $N = scalar @doc_vector - 1;
	my $Rel = scalar @rel_list;
	my $temp = 0;

	for (my $i = 0; $i < $Rel; $i++) {
		$temp += $rel_rank{$rel_list[$i]}; 
	}
	return 1 - ($temp - (1 + $Rel)*$Rel/2) / ($Rel * ($N - $Rel));
}

sub cal_prec_norm {
	my $N  = scalar @doc_vector - 1;
	my $Rel = scalar @rel_list;
	my $sum_rank = 0;
	my $sum_i = 0; 

	for (my $i = 0; $i < $Rel; $i++) {
		$sum_rank += log( $rel_rank{$rel_list[$i]});
		$sum_i += log($i + 1);
	}
	
	return 1 - ($sum_rank - $sum_i) / ($N * log($N) - ($N - $Rel)*log($N - $Rel) - $Rel * log($Rel));
}

##########################################################
## SHOW_RELVNT
## 
##
## arrays described in &show_retrieved_set and &comp_recall
## and print out only the relevant documents, in an order
## and manner of presentation very similar to &show_retrieved_set.
##########################################################

sub show_relvnt {

    my $rel_hash   = shift;
    my $qry_num    = shift;
    my $qry_vect   = shift;

    print << "EndOfList";

    ************************************************************
	Relevant Documents of Query number $qry_num
    ************************************************************
    Similarity   Doc#  Author      Title
    ==========   ==== ========     =============================

EndOfList
    ;


    my $rel_num = ($qry_num =~ /^\d$/) ? "0$qry_num" : $qry_num;
	
	for my $i (0 .. scalar @rel_list - 1) {
		my $ind = $rel_list[$i];
		
		print "  ";
		

		my ($similarity) = ($doc_simula[$ind]    =~ /^([0-9]+\.\d{0,8})/);
		if (!(defined $similarity)) {	# FIXME: why would this happen?
			$similarity = sprintf "%0.8f", 0;	
		}

		my  $title       = substr $titles_vector[$ind], 0, 47;


		print "  ", $similarity, "   ", $title, "\n";
    }
	print "\n";
}



########################################################
## SHOW_OVERLAP
## 
## Parameters:
##  - Two vectors ($qry_vect and $doc_vect), passed by
##    reference.
##  - The number of the vectors for display purposes
##
## 
## This function should show the terms that two vectors
## have in common, the relative weights of these terms
## in the two vectors, and any additional useful information
## such as the document frequency of the terms, etc.
##
## Useful for understanding the reason why documents
## are judged as relevant. 
##
## Present in a sorted order most informative to the user.
##
########################################################

sub show_overlap {

    my $qry_vect = shift;
    my $doc_vect = shift;
    my $qry_num  = shift;
    my $doc_num  = shift;

    print "============================================================\n";
    printf( "%-15s  %8d  %8d\t%s\t\n", 
	   "Vector Overlap",
	   $qry_num        ,
	   $doc_num        ,
	   "");
    printf( "%-15s  %-12s  %-12s %-10s\t\n", 
	   "Terms",
	   "Query Weight"       ,
	   	"Doc Weight"      ,
	   "Docfreq");    
    print "============================================================\n";

    my $term_one   = undef;
    my $weight_one = undef;

    while (($term_one, $weight_one) = each %{ $qry_vect }) {
		if (exists $$doc_vect{ $term_one }) {

			printf( "%-15s  %0.8f  %0.8f  \t%d\n"    ,
			   $term_one                    ,
			   $weight_one                  ,
			   $$doc_vect{ $term_one }      ,
			   $docs_freq_hash{ $term_one } ,
			   );
		}
    }
}


########################################################
## DO_FULL_COSINE_SIMILARITY
## 
##  Prompts for a document number and query number,
##  and then calls a function to show similarity.
##
##  Could/should be expanded to handle a variety of
##  similarity measures.
########################################################

sub do_full_cosine_similarity {

    print "\n";
    print "1st Document number: ";

    my    $num_one = <STDIN>;
    chomp $num_one;

    print "\n";
    print "2nd Document number: ";
    
    my    $num_two = <STDIN>;
    chomp $num_two;

    $num_one = 1 if $num_one !~ /[0-9]/;
    $num_two = 1 if $num_two !~ /[0-9]/;

    full_cosine_similarity( $doc_vector[$num_one],
			    $doc_vector[$num_two],
			    $num_one,
			    $num_two );
}


########################################################
## FULL_COSINE_SIMILARITY
## 
## 
## This function should compute cosine similarity between
## two vectors and display the information that went into
## this calculation, useful for debugging purposes.
## Similar in structure to &show_overlap.
########################################################
 
sub full_cosine_similarity {

    my $qry_vect = shift;
    my $doc_vect = shift;
    my $qry_indx = shift;
    my $doc_indx = shift;

    print << "EndOfList";

    *************************************************************
	Similarity between Doc No.$doc_indx amd Doc No.$qry_indx
    *************************************************************
    Cosine Similarity   Doc#  Author      Title
    =================   ==== ========     =============================

EndOfList
    ;
	
	print "  ";
	
	my $similarity = sprintf "%0.8f", &cosine_sim_a($qry_vect, $doc_vect);
	my $title = substr $titles_vector[$doc_indx], 0, 47;

	print "    ", $similarity, "        ", $title, "\n";
	print "\n";

}


##########################################################
##  FULL_PRECISION_RECALL_TEST
##
##  This function should test the various precision/recall 
##  measures discussed in the assignment and store cumulative
##  statistics over all queries.
##
##  As each query takes a few seconds to process, print
##  some sort of feedback for each query so the user
##  has something to watch.
##
##  It is helpful to also log this information to a file.
##
##  Suggestion: run in a wide window
##
##########################################################

sub full_precision_recall_test {

    # using global variables to store cumulative
    # statistics, initialize them here.
	
	@result_list = ();

#    for my $ind ( 1 .. $tot_queries ) {
#
#	&get_retrieved_set( $qry_vector[$ind] );
#	&comp_recall( $relevance_hash{ $ind }, $ind );
#
#	# Suggestion: Collect cumulative statistics here or in
#	#             global variables set in the above funtion
#    }
    
    # Suggestion: Print some sort of summary here.

	print << "EndOfList";

    ************************************************************
	Full averaged precision/recall measures for all 33 queries
    ************************************************************
    Permutation\t\tP_0.25   P_0.50   P_0.75   P_1.00   P_mean1   P_mean2   P_norm   R_norm
    ===========\t\t======== ======== ======== ======== ========= ========= ======== ========

EndOfList
    ;
	
# 8 permutations in total
	my	@perms = ("Default", "Raw TF", "Boolean", "Dice", "Raw_tokens", "All tokens", "Equal weight", "Abstract4x"); 
	
	for (my $p = 0; $p < scalar @perms; $p++) {


		#	Default
		if ($p == 0) {
			&init_files ( "stemmed" );
			&init_qry_vectors;
			&init_doc_vectors;
			for my $i (1 .. 33) {
				my $index = ($i =~ /^d$/) ? "0$i" : $i;
				&get_retrieved_set( $qry_vector[$index] , "cosine");
				&comp_recall( $relevance_hash{$index}, $index);
			}
		}
		
		#	Raw TF weighting
		if ($p == 1) {
			&init_doc_vectors("raw_tf");
			&init_qry_vectors("raw_tf");
			for my $i (1 .. 33) {
				&get_retrieved_set( $qry_vector[ $i ], "cosine");
				&comp_recall( $relevance_hash{$i}, $i);	
			}
		}

		# Boolean weighting
		if ($p == 2) {
			&init_doc_vectors("boolean");
			&init_boolean_qry_vectors;
			for my $i (1 .. 33) {
				&get_retrieved_set( $qry_vector[ $i ], "cosine");
				&comp_recall( $relevance_hash{$i}, $i);	
			}
		}

		# Dice Similarity
		if ($p == 3) {
			&init_doc_vectors;
			&init_qry_vectors;		# Initialize the original vectors
			for my $i (1 .. 33) {
				my $index = ($i =~ /^d$/) ? "0$i" : $i;

				&get_retrieved_set( $qry_vector[ $index ], "dice");
				&comp_recall( $relevance_hash{$index}, $index);	
			}
		}

		# Raw, unstemmed tokens
		if ($p == 4) {
			&init_files ( "unstemmed" );
			&init_corp_freq;
			&init_doc_vectors;
			&init_qry_vectors;		# Initialize the original vectors
	
			for my $i (1 .. 33) {
				my $index = ($i =~ /^d$/) ? "0$i" : $i;
				
				&get_retrieved_set( $qry_vector[ $index ], "cosine");
				&comp_recall( $relevance_hash{$index}, $index);	
			}
			&init_files ( "stemmed" );	# Set back to default
		}
		
		#	Include all tokens, including punctuation
		if ($p == 5) {
			&init_corp_freq(0);
			&init_doc_vectors("all");
			&init_qry_vectors("all");		# Initialize the original vectors
			for my $i (1 .. 33) {
				my $index = ($i =~ /^d$/) ? "0$i" : $i;

				&get_retrieved_set( $qry_vector[ $index ], "cosine");
				&comp_recall( $relevance_hash{$index}, $index);	
			}
		}

		# Weights each part equally
		if ($p == 6) {
			&init_corp_freq;
			&init_doc_vectors("default",1,1,1,1);
			&init_qry_vectors;		# Reset default settings
			for my $i (1 .. 33) {
				my $index = ($i =~ /^d$/) ? "0$i" : $i;

				&get_retrieved_set( $qry_vector[ $index ], "cosine");
				&comp_recall( $relevance_hash{$index}, $index);	
			}
		}
		
		# Weight: 1, 1, 1, 4
		if ($p == 7) {
			&init_corp_freq;
			&init_doc_vectors("default",1,1,1,4);
			&init_qry_vectors;		# Reset default settings
			for my $i (1 .. 33) {
				my $index = ($i =~ /^d$/) ? "0$i" : $i;

				&get_retrieved_set( $qry_vector[ $index ], "cosine");
				&comp_recall( $relevance_hash{$index}, $index);	
			}
		}
		
		print "      $perms[$p]\t\t";
		for my $i (0 .. scalar @result_list - 1) {
			my $tmp = sprintf "%.4f",  $result_list[$i] / 33;
			print "$tmp\t";
		}
		print "\n\n";
		@result_list = ();

	}


}


########################################################
## COSINE_SIM_A
## 
## Computes the cosine similarity for two vectors
## represented as associate arrays.
########################################################

sub cosine_sim_a {

    my $vec1 = shift;
    my $vec2 = shift;

    my $num     = 0;
    my $sum_sq1 = 0;
    my $sum_sq2 = 0;

    my @val1 = values %{ $vec1 };
    my @val2 = values %{ $vec2 };

    # determine shortest length vector. This should speed 
    # things up if one vector is considerable longer than
    # the other (i.e. query vector to document vector).

    if ((scalar @val1) > (scalar @val2)) {
	my $tmp  = $vec1;
	   $vec1 = $vec2;
	   $vec2 = $tmp;
    }

    # calculate the cross product

    my $key = undef;
    my $val = undef;

    while (($key, $val) = each %{ $vec1 }) {
	$num += $val * ($$vec2{ $key } || 0);
    }

    # calculate the sum of squares

    my $term = undef;

    foreach $term (@val1) { $sum_sq1 += $term * $term; }
    foreach $term (@val2) { $sum_sq2 += $term * $term; }
	
	if ($sum_sq1 * $sum_sq2 == 0) {
		return 0;
	}
    return ( $num / sqrt( $sum_sq1 * $sum_sq2 ));
}


########################################################
##  COSINE_SIM_B
##  
##  This function assumes that the sum of the squares
##  of the term weights have been stored in advance for
##  each document and are passed as arguments.
########################################################

sub cosine_sim_b {

    my $vec1 = shift;
    my $vec2 = shift;

    my $sum_sq1 = shift;
    my $sum_sq2 = shift;

    my $num     = 0;
    my $key     = undef;
    my $val     = undef;

    while (($key, $val) = each %{ $vec1 }) {
	$num += $val * $$vec2{ $key };
    }

    return ( $num / sqrt( $sum_sq1 * $sum_sq2 ));
}

########################################################
##  DICE_SIM
########################################################

sub dice_sim {

    my $vec1 = shift;
    my $vec2 = shift;

    my $num     = 0;
    my $sum_sq1 = 0;
    my $sum_sq2 = 0;

    my @val1 = values %{ $vec1 };
    my @val2 = values %{ $vec2 };

    # determine shortest length vector. This should speed 
    # things up if one vector is considerable longer than
    # the other (i.e. query vector to document vector).

    if ((scalar @val1) > (scalar @val2)) {
	my $tmp  = $vec1;
	   $vec1 = $vec2;
	   $vec2 = $tmp;
    }

    # calculate the cross product

    my $key = undef;
    my $val = undef;

    while (($key, $val) = each %{ $vec1 }) {
		$num += $val * ($$vec2{ $key } || 0);
    }

    # calculate the sum of squares

    my $term = undef;

    foreach $term (@val1) { $sum_sq1 += $term; }
    foreach $term (@val2) { $sum_sq2 += $term; }
	
	if (($sum_sq1 + $sum_sq2) eq 0) {
		if ($num eq 0) {
			return 0;
		}
		return 1;	
	}
    return ( $num * 2 / ( $sum_sq1 + $sum_sq2 ));
}
